{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Second Part of the Assignment of IDS 2020-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b>Student Name and matriculation number:\n",
    "    \n",
    "    Mridul Mani Tripathi - 403587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inflect needed to convert numbers to words (for Question 2)\n",
    "!pip install inflect\n",
    "# (for Question 1.4 )\n",
    "!pip install -U gensim\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stack as defined in software\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, normalize\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from p_decision_tree.DecisionTree import DecisionTree\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# internals\n",
    "import inspect\n",
    "from typing import NewType\n",
    "import itertools\n",
    "import functools as func\n",
    "import operator\n",
    "\n",
    "# inflect needed to convert numbers to words (for Question 2)\n",
    "import inflect\n",
    "# seaborn for distribution\n",
    "import seaborn as sns\n",
    "\n",
    "rand_seed = 403596\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdsType = NewType('IdsType',str)\n",
    "\n",
    "class IdsTypes:\n",
    "    time = IdsType('Time')\n",
    "    num = IdsType('Numerical')\n",
    "    cat = IdsType('Categorical')\n",
    "    bl = IdsType('Boolean')\n",
    "\n",
    "class Column(str):  \n",
    "    def __new__(cls,name:str,idstype:IdsType):\n",
    "        obj = str.__new__(cls,name)\n",
    "        obj.idstype = idstype\n",
    "        return obj\n",
    "    \n",
    "class CatCol(Column):\n",
    "    def __new__(cls,name:str):\n",
    "        obj = Column.__new__(cls,name, IdsTypes.cat)\n",
    "        return obj\n",
    "    \n",
    "    def convert(self,ds_col):\n",
    "        return pd.Categorical(ds_col)\n",
    "    \n",
    "class NumCol(Column):\n",
    "    def __new__(cls,name:str):\n",
    "        obj = Column.__new__(cls,name, IdsTypes.num)\n",
    "        return obj\n",
    "    \n",
    "    def convert(self,ds_col):\n",
    "        return pd.to_numeric(ds_col)\n",
    "\n",
    "class BoolCol(Column):\n",
    "    def __new__(cls, name:str):\n",
    "        obj = Column.__new__(cls,name,IdsTypes.bl)\n",
    "        return obj\n",
    "\n",
    "    def convert(self, col):\n",
    "        return col.astype('bool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Data Preprocessing and Data Quality (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizData:\n",
    "    file_name = './Datasets/DataPrepViz.csv'\n",
    "    sampled_file_name = './output/dataPrepViz_sampled.csv'\n",
    "    __original_ds__ = None\n",
    "    __sampled_ds__ = None\n",
    "    \n",
    "    def load_original(force_reload = False):\n",
    "        if force_reload or VizData.__original_ds__ is None:\n",
    "            VizData.__original_ds__ = VizData.apply_categories(pd.read_csv(VizData.file_name, sep=\";\"))\n",
    "        return VizData.__original_ds__.copy()\n",
    "    \n",
    "    def load_sampled(force_reload = False):        \n",
    "        if force_reload or VizData.__sampled_ds__ is None:\n",
    "            VizData.__sampled_ds__ = VizData.apply_categories(pd.read_csv(VizData.sampled_file_name, index_col=0))\n",
    "        return VizData.__sampled_ds__.copy()\n",
    "    \n",
    "    def apply_categories(df):\n",
    "        for w in VizData.Cols.as_set():\n",
    "            df[w] = w.convert(df[w])\n",
    "        return df\n",
    "\n",
    "    class Cols:\n",
    "        geog = CatCol('geographic_group')\n",
    "        country = CatCol('country')\n",
    "        fert = NumCol('children_per_woman_total_fertility')\n",
    "        child_mort = NumCol('child_mortality_0_5_year_olds_dying_per_1000_born')\n",
    "        co2 = NumCol('co2_emissions_tonnes_per_person')\n",
    "        corruption = NumCol('corruption_perception_index_cpi')\n",
    "        life_exp = NumCol('life_expectancy_years')\n",
    "        vccn_eff = NumCol('vccin_effect_dag')\n",
    "\n",
    "\n",
    "        __intset__ = None\n",
    "        __transdict__ = None\n",
    "\n",
    "        def _intset_():\n",
    "            if VizData.Cols.__intset__ is None:\n",
    "                VizData.Cols.__intset__ = frozenset({val for _,val in inspect.getmembers(VizData.Cols, lambda attr:isinstance(attr,Column))})\n",
    "            return VizData.Cols.__intset__\n",
    "            \n",
    "            \n",
    "        def _transdict_():\n",
    "            if VizData.Cols.__transdict__ is None:\n",
    "                VizData.Cols.__transdict__ = {v:v for v in VizData.Cols.as_set()}\n",
    "            return VizData.Cols.__transdict__\n",
    "            \n",
    "        def as_set():\n",
    "            return {v for v in VizData.Cols._intset_()}\n",
    "        \n",
    "        def as_list():\n",
    "            return [v for v in VizData.Cols._intset_()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Carry out the following preprocessing steps before starting the analysis:\n",
    "\n",
    "Select 90% of dataset <b>dataPrepViz.csv</b> for this assignment by random sampling. Use the matriculation number of one of the group members as seed. Rename the sampled dataset to <b>dataPrepViz_sampled</b> and export it as CSV.\n",
    "\n",
    " - <font color='red'>Important!</font> Make sure that you submit your extracted dataset with your results in Moodle.\n",
    "\n",
    "Use this dataset <b>dataPrepViz_sampled</b> as starting point for Question 1 and Question 2. Then apply further modifications as specified in the those questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q1_a:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def run(self):\n",
    "        sampled = self.df.sample(frac=0.9, random_state=rand_seed)\n",
    "        sampled.to_csv(VizData.sampled_file_name)\n",
    "        return sampled\n",
    "\n",
    "dataPrepViz_sampled = Q1_a(VizData.load_original()).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPrepViz_sampled = VizData.load_sampled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dataset <b>data1</b> by removing the feature 'geographic_group' from <b>dataPrepViz_sampled</b>. Use this <b>data1</b> dataset for Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = dataPrepViz_sampled.drop(columns=[VizData.Cols.geog])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) We want to get a first impression of the data. To achieve this, compute and show the following:\n",
    "\n",
    "- the column names (the names of the features)\n",
    "- the data type of each feature\n",
    "- for categorical features: the number of classes and the value of the most frequent class\n",
    "- for numerical features: the mean, standard deviation, minimum and maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q1_b:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "            \n",
    "    def run(self):\n",
    "        self.column_dt()\n",
    "        self.cat_stat()\n",
    "        self.num_stat()\n",
    "        return self\n",
    "\n",
    "    def column_dt(self):\n",
    "        print('-----------')\n",
    "        print('Feature names and types:')\n",
    "        display(self.df.dtypes)\n",
    "\n",
    "    def cat_stat(self):\n",
    "        print('---------')\n",
    "        print('Categorical stats:')\n",
    "        display(self.df.select_dtypes(['category']).describe())\n",
    "\n",
    "    def num_stat(self):\n",
    "        print('---------')\n",
    "        print('Numerical stats:')\n",
    "        display(self.df.select_dtypes(['float64']).describe())\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "q1_b = Q1_b(data1).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) For each feature, provide a histogram (with at least 10 bins each) showing the value distribution. Can you spot any obvious data quality issues, e.g. inconsistencies, implausible values or missing values (without researching on specific domain knowledge)?\n",
    "\n",
    "Briefly explain the issues you identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Q1_c:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def run(self, m = 3, bins=11):\n",
    "        n = (self.df.shape[1]//m + (self.df.shape[1]%m > 0))\n",
    "        f, axs = plt.subplots( n, m, sharey=True)\n",
    "        for i,feature in enumerate(self.df.columns.values):\n",
    "            sns.histplot(data=self.df, x=feature, ax=axs[i//m, i%m], bins=bins)\n",
    "\n",
    "        f.tight_layout()\n",
    "        return self\n",
    "\n",
    "q1_c = Q1_c(data1).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "* `children_per_woman_total_fertility` contains negative values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Substitute all implausible values as missing data (numpy.nan). Show the scatter matrix of the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Q1_d:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def run(self):\n",
    "        for c in self.df.select_dtypes(['float64']).columns.values:\n",
    "            self.df[self.df[c] < 0] = np.nan\n",
    "        sns.pairplot(self.df, kind='scatter')\n",
    "        return self\n",
    "\n",
    "q1_d = Q1_d(data1).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) We need to handle any implausible or missing data. In the lecture, several strategies to do so have been introduced. \n",
    "\n",
    "In this question, consider implausible values to be the ones identified in part (c).\n",
    "\n",
    "    1) For all numerical features, compute and show mean, standard deviation, minimum and maximum, while ignoring the missing and implausible values. Also, print the total number of data rows.\n",
    "    \n",
    "    2) Based on the information obtained in the previous subtasks of this question, choose a strategy for handling all missing/implausible values, such that\n",
    "    - for one feature, you delete all data rows that include a missing value.\n",
    "    - for one feature, you replace all missing values by the median value.\n",
    "    - for one feature, you impute the values based on other, continous features using a regression classifier.\n",
    "    Create a cleaned dataset with all those values handled accordingly. \n",
    "    \n",
    "    3) For all numerical features, compute and show mean, standard deviation, minimum and maximum with respect to your cleaned dataset. Also print the total number of data rows.\n",
    "    \n",
    "    4) Motivate and explain the choices you made in 2). Compare the computed statistical values before and after cleaning and briefly describe and evaluate any changes.\n",
    " \n",
    "*Hint: There might not be an obvious choice for the best strategy. In this case, sound reasoning based on correct observations is more important than the decision itself.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class Q1_e:\n",
    "    numerical_features = []\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def run(self):\n",
    "        before = self.stats_before()\n",
    "        df = self.df\n",
    "        df = Q1_e.drop_rows(df)\n",
    "        df = Q1_e.substitute_median(df)\n",
    "        self.df = Q1_e.interpolate_regr(df)\n",
    "        after = self.stats_after()\n",
    "        print('--------')\n",
    "        print('differences old v new')\n",
    "        display(after - before)\n",
    "        return self\n",
    "\n",
    "    def drop_rows(df, feature=VizData.Cols.country):\n",
    "        return df.drop(labels=df[df[feature].isnull()].index.values)\n",
    "\n",
    "    def interpolate_regr(df, feature=VizData.Cols.vccn_eff):\n",
    "        df_nn = df[df[feature].notnull()]\n",
    "        X = df_nn.drop(columns=[feature]).select_dtypes(['float64'])\n",
    "        y = df_nn[feature]\n",
    "        clf=LinearRegression().fit(X,y)\n",
    "        X_inp = df.drop(columns=[feature]).select_dtypes(['float64'])\n",
    "        for i in df[df[feature].isnull()].index.values:\n",
    "            pred = clf.predict(X_inp.loc[[i]])\n",
    "            if pred < 0:\n",
    "                pred = 0\n",
    "            df[feature].loc[i] = pred\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def substitute_median(df, feature=VizData.Cols.corruption):\n",
    "        med = df[feature].median()\n",
    "        df[feature] = df[feature].fillna(med)\n",
    "        return df\n",
    "\n",
    "    def stats_before(self):\n",
    "        print('-------')\n",
    "        print('Numerical feature stats before cleaning:')\n",
    "        pdf = pd.DataFrame({feature:[d.mean(), d.std(), d.min(), d.max(), d.notnull().sum()] for feature, d in self.df.select_dtypes(['float64']).iteritems() }).set_index(pd.Series(['mean', 'std', 'min', 'max', '# values']))\n",
    "        print(len(self.df.notnull()))\n",
    "        display(pdf)\n",
    "        return pdf\n",
    "\n",
    "    def stats_after(self):\n",
    "        print('-------')\n",
    "        print('Numerical feature stats after cleaning:')\n",
    "        pdf = pd.DataFrame({feature:[d.mean(), d.std(), d.min(), d.max(), d.notnull().sum()] for feature, d in self.df.select_dtypes(['float64']).iteritems() }).set_index(pd.Series(['mean', 'std', 'min', 'max', '# values']))\n",
    "        print(len(self.df))\n",
    "        display(pdf)\n",
    "        return pdf\n",
    "\n",
    "q1_e = Q1_e(q1_d.df).run()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: Techniques and their columns:\n",
    "* _delete rows with missing values_: We applied this strategy to the `country` feature, as it is categorical and we would have had no way to (realisticly) compute missing values\n",
    "* _replace missing values with median_: Applied to `corruption_perception_index_cpi`, since there is only 1 additional value missing. Hence this naive way of handling the missing data will have a much lesser impact then on the other features\n",
    "* _impute values_: Applied to `vccin_effect_dag`, since here 49 values had to be replaced. Hence the impact was reduced, as is visible by the comparison table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Data Preprocessing and Advanced Visualization (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, use the <b>dataPrepViz_sampled</b> dataset you created in Q1, part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) To create a suitable input for the following questions, modify the dataset as listed below:\n",
    "\n",
    "    1) remove rows that contain negative values\n",
    "    2) remove all rows that contain missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q2_a:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def run(self):\n",
    "        for c in self.df.select_dtypes(['float64']).columns.values:\n",
    "            self.df[self.df[c] < 0] = np.nan\n",
    "        self.df.dropna(inplace=True)\n",
    "        return self\n",
    "q2_a = Q2_a(dataPrepViz_sampled).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) For this subtask remove the feature 'country' from the data. Create four parallel coordinate plots that visualize the relation between the numerical attributes for all geographic groups.\n",
    "\n",
    "    1) For the first parallel coordinate plot, use the values unchanged.\n",
    "    \n",
    "    2-4) For the remaining 3 parallel coordinate plots, first normalize all numerical attributes by mapping them individually to the interval between 0 and 1, that is, apply Min-max normalization. Draw the three plots with different orderings of the features (randomized or chosen by interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "class Q2_b:\n",
    "    args = {\"color\":('#327125', '#D4BF00', '#E821AC', '#1928E4', '#CC3800', '#373737' )}\n",
    "    def __init__(self, df):\n",
    "        self.df = df.drop(columns=[VizData.Cols.country])\n",
    "\n",
    "    def run(self):\n",
    "        \n",
    "        parallel_coordinates(self.df, VizData.Cols.geog,  **Q2_b.args)\n",
    "        df_scaled = Q2_b.scale(self.df)\n",
    "        f, axs = plt.subplots(3,1, figsize=(16,18))\n",
    "        parallel_coordinates(df_scaled[[VizData.Cols.fert, VizData.Cols.co2, VizData.Cols.corruption, VizData.Cols.life_exp, VizData.Cols.vccn_eff, VizData.Cols.geog, VizData.Cols.child_mort]],  VizData.Cols.geog, ax=axs[0], **Q2_b.args)\n",
    "        parallel_coordinates(df_scaled[[VizData.Cols.co2, VizData.Cols.fert,  VizData.Cols.corruption, VizData.Cols.vccn_eff, VizData.Cols.life_exp,  VizData.Cols.geog, VizData.Cols.child_mort]],  VizData.Cols.geog, ax=axs[1], **Q2_b.args)\n",
    "        parallel_coordinates(df_scaled[[VizData.Cols.corruption, VizData.Cols.co2,  VizData.Cols.life_exp, VizData.Cols.vccn_eff, VizData.Cols.fert,   VizData.Cols.geog, VizData.Cols.child_mort]],  VizData.Cols.geog, ax=axs[2], **Q2_b.args)\n",
    "        \n",
    "        \n",
    "        return self\n",
    "\n",
    "    def scale(df):\n",
    "        df_scaled = df.copy()\n",
    "        for c in df_scaled.select_dtypes(['float64']).columns.values:\n",
    "            df_scaled[c] = MinMaxScaler().fit_transform(np.array(df[c]).reshape(-1,1))\n",
    "        return df_scaled\n",
    "\n",
    "\n",
    "q2_b = Q2_b(q2_a.df).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) For each of the questions 1-3 below:\n",
    "- Indicate all of your parallel coordinate plots, which are suitable for finding an answer to the question. Explain your selection. \n",
    "- If possible, briefly answer the questions.\n",
    "\n",
    "    1) Is there a correlation between fertility and CO2 emissions? If yes, is it positive or negative?\n",
    "\n",
    "    2) Is there a correlation between life expectancy and vaccination confidence? If yes, is it positive or negative?\n",
    "\n",
    "    3) Is there a correlation between CO2 emissions and perceived corruption? If yes, is it positive or negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "The plots have been chosen so that the features in question were neighbours.\n",
    "\n",
    "1. (Scaled plots 1 & 2): As there are multiple lines crossing each other, pratially in clusters, there seems to be a negative correlation between those.\n",
    "2. (All scaled plots): While there again are some lines crossing each other, they are more sparse, while most lines are nearly parallel, indicating a positive correlation.\n",
    "3. (Scaled plots 1 & 3): Again, it looks more like a positive correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) In this subtask we prepare the data for the heat map, which we create in subtask (e). \n",
    "\n",
    "The heat map should visualize the vaccination confidence ('vccin_effect_dag') for different combinations of CO2 emissions ('co2_emissions_tonnes_per_person') and fertility ('children_per_woman_total_fertility'). The heatmap should have 40 columns and 40 rows. The shown vaccination confidence value should be the *median* of all values for each combination of CO2 emissions and fertility. \n",
    "\n",
    "Do the following steps in preparation:\n",
    "\n",
    "    1) First, drop all columns that are not needed in this task.\n",
    "\n",
    "    2) Discretize the CO2 emissions and fertility data into 40 bins each, using equal-width binning.\n",
    "\n",
    "    3) Group the data by CO2 emissions and fertility, using median to aggregate the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q2_d:\n",
    "    target_feature = VizData.Cols.vccn_eff\n",
    "    exp_features = [VizData.Cols.co2, VizData.Cols.fert]\n",
    "    heatmap_size = (40,40)\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df[Q2_d.exp_features + [Q2_d.target_feature]].copy()\n",
    "\n",
    "    def run(self):\n",
    "        for i,ef in enumerate( Q2_d.exp_features):\n",
    "            self.df[ef] = pd.cut(self.df[ef], bins=Q2_d.heatmap_size[i])\n",
    "        self.df = self.df.groupby(Q2_d.exp_features).median()\n",
    "        self.df.reset_index(inplace=True)\n",
    "        self.df = self.df.pivot(index=Q2_d.exp_features[0], columns=Q2_d.exp_features[1], values=Q2_d.target_feature)\n",
    "\n",
    "        return self\n",
    "\n",
    "q2_d = Q2_d(VizData.load_sampled()).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Use the modified data to create a heat map as specified in part (d). Answer the following questions based on that heat map and briefly explain how you derived your answer:\n",
    "\n",
    "    1) Which combination of bins results in the highest vaccination confidence? \n",
    "    \n",
    "    2) How do you explain empty fields in your heat map?\n",
    "    \n",
    "    3) Can you identify any pattern in the heat map, e.g. in the coloring or in the distribution of empty fields? What can be a possible reason for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q2_e:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def run(self):\n",
    "        f, ax = plt.subplots(figsize=(20, 8))\n",
    "        sns.heatmap(self.df, annot=True, ax=ax)\n",
    "        bottom, top = ax.get_ylim()\n",
    "        ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "        return self\n",
    "\n",
    "q2_e = Q2_e(q2_d.df).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "1) Biggest confidence is 0.18 for fertility (-10.017, -9.568] and emissions (10.865, 11.467]. Looking at the highest value in ranges which are valid, it would be 0.15 for fertility (1.238, 1.671] and emissions (4.849, 5.451]\n",
    "\n",
    "2) There aren't any values for the combination of those bins\n",
    "\n",
    "3) Besides there beeing an awfull lot of white space, the valid part of the data gets lighter while moving to lower bins of the fertility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Frequent Item Sets and Association Rules (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import association_rules as arule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoreData:\n",
    "    file_name = './Datasets/store_data.csv'\n",
    "    cleaned_file_name = 'store_data_2.csv'\n",
    "    __original_ds__ = None\n",
    "    __cleaned_ds__ = None\n",
    "    \n",
    "    def load_original(force_reload = False):\n",
    "        if force_reload or StoreData.__original_ds__ is None:\n",
    "            csv_ds = StoreData.get_csv(StoreData.file_name)\n",
    "            StoreData.__original_ds__ = StoreData.csv_to_pandas(csv_ds)\n",
    "        return StoreData.__original_ds__.copy()\n",
    "    \n",
    "    def load_cleaned(force_reload = False):        \n",
    "        if force_reload or StoreData.__cleaned_ds__ is None:\n",
    "            csv_ds = StoreData.get_csv(StoreData.cleaned_file_name)\n",
    "            StoreData.__cleaned_ds__ = StoreData.csv_to_pandas(csv_ds)\n",
    "        return StoreData.__cleaned_ds__.copy()\n",
    "    \n",
    "    def get_csv(filename):\n",
    "        data_set = list()\n",
    "        with open(filename, 'r') as csvFile:\n",
    "            reader = csv.reader(csvFile)\n",
    "            for row in reader:\n",
    "                data_set.append(list([i for i in row if i != '']))\n",
    "        return data_set\n",
    "    \n",
    "    def csv_to_pandas(csv_ds):\n",
    "        te = TransactionEncoder()\n",
    "        te_t = te.fit(csv_ds).transform(csv_ds)\n",
    "        df = pd.DataFrame(te_t, columns=te.columns_)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Carry out some preprocessing steps before starting the analysis:\n",
    " - Select 90% of the <b>store_data</b> dataset by random sampling. Use the matriculation number of one of the group members as seed.\n",
    " - After completing this preprocessing step, export your final dataset as <b>store_data_2.csv</b> dataset and use it for the next steps of the assignment.\n",
    " - <font color='red'>Important!</font> Make sure that you submit your extracted dataset with your results in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q3_a:\n",
    "    def run(self):\n",
    "        csv_ds = StoreData.get_csv(StoreData.file_name)\n",
    "        n = len(csv_ds) * 0.9\n",
    "        n = math.ceil(n)\n",
    "        random.seed(rand_seed)\n",
    "        sampled = [csv_ds[i] for i in sorted(random.sample(range(len(csv_ds)),n))]\n",
    "        with open(StoreData.cleaned_file_name, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(sampled)\n",
    "        return self\n",
    "\n",
    "q3_a = Q3_a().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Find the most frequent itemsets with the support of more than 0.04 using the Apriori algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " class Q3_b:\n",
    "    def run(self):\n",
    "        df = StoreData.load_cleaned()\n",
    "        frequent_itemsets = apriori(df, min_support = 0.04, use_colnames = True)\n",
    "        display(frequent_itemsets.sort_values(by=['support'], ascending=False).head(5))\n",
    "        self.freq_sets = frequent_itemsets.copy()\n",
    "        return self\n",
    "    \n",
    "q3_b = Q3_b().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Find the most frequent itemsets with more than 1 member and a support of more than 0.04 using the Apriori algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q3_c:\n",
    "    def __init__(self, freq_sets):\n",
    "        self.freq_sets = freq_sets\n",
    "        \n",
    "    def run(self):\n",
    "        frequent_itemsets = self.freq_sets\n",
    "        frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "        frequent_itemsets_filtered = frequent_itemsets[(frequent_itemsets['length'] > 1)]  \n",
    "        display(frequent_itemsets_filtered.sort_values(by=['support', 'length'], ascending=False).head(5))\n",
    "        return self\n",
    "q3_c = Q3_c(q3_b.freq_sets.copy()).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Find the itemsets having min_confidence=0.3 and min_lift=1.2. Print support, confidence, and lift of the filtered rules in one table. How do you interpret the quality of the discovered rules?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q3_d:\n",
    "    def __init__(self, freq_sets):\n",
    "        self.freq_sets = freq_sets\n",
    "        \n",
    "    def run(self):\n",
    "        df = StoreData.load_cleaned()\n",
    "        frequent_itemsets = apriori(df, min_support = 0.04, use_colnames=True)\n",
    "        rules = arule(frequent_itemsets, metric = 'lift', min_threshold = 1.2)\n",
    "        display(rules[(rules['confidence'] > 0.3)].drop(columns=[\"leverage\", \"conviction\"]))\n",
    "        return self\n",
    "q3_d = Q3_d(q3_b.freq_sets.copy()).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "When taking a look at the combined support of the rules, it is relatively low. Same for the antecedent support. When looking at the consequent support, it becomes clear why mineral water is the consequent for all 4 filtered rules (nearly .25!). When looking at the lift values, they are well over 1, indicating that the rules appear much more often then expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Apply the FP-Growth algorithm for all the settings of b, c, and d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "class Q3_e:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def run(self):\n",
    "        f_items = self.fpg()\n",
    "        c = Q3_c(f_items).run()\n",
    "        d = Q3_d(f_items).run()\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def fpg(self):\n",
    "        frequent_itemsets = fpgrowth(self.df, min_support = 0.04, use_colnames = True)\n",
    "        display(frequent_itemsets.sort_values(by=['support'], ascending=False).head(5))\n",
    "        return frequent_itemsets\n",
    "\n",
    "q3_e = Q3_e(StoreData.load_cleaned()).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Text Mining (15 points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we use <b>sms_data.csv</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import string\n",
    "import multiprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from numpy.random import RandomState\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Texts:\n",
    "    right_padding = '<'\n",
    "    left_padding = '>' \n",
    "    cc = multiprocessing.cpu_count()\n",
    "    \n",
    "    def default_regressor():\n",
    "        return LogisticRegression(random_state=rand_seed, solver='liblinear', multi_class= 'auto')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load the dataset and create the <b>sampled_data</b> dataset which includes 90% of the data. Use the matriculation number of one of the group members as seed. Export the sampled dataset. Split the sampled data into training (80%) and test (20%) data preserving the distribution based on \"Label\".\n",
    "\n",
    "<font color='red'>Important!</font> Make sure that you submit your extracted dataset with your results in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q4_a:\n",
    "\n",
    "    def run(self):\n",
    "        self.df = pd.read_csv('./Datasets/sms_data.csv', sep=\";\", encoding='cp1252').sample(frac=0.9, random_state=rand_seed)\n",
    "        self.df['Label'] = self.df['Label'].astype('category')\n",
    "        self.df['Text'] = self.df['Text'].astype('str')\n",
    "        self.df.to_csv('./output/sms_sampled.csv')\n",
    "        X = self.df[\"Text\"]\n",
    "        y = self.df[\"Label\"]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, train_size=0.8, random_state=rand_seed, stratify=y)\n",
    "        self.train = (self.X_train, self.y_train)\n",
    "        self.test = (self.X_test, self.y_test)\n",
    "        return self\n",
    "\n",
    "q4_a = Q4_a().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "In the following tasks, train each of the specified models with the training data and give for each the accuracy on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Model based on the binary document-term matrix\n",
    "\n",
    "Perform preprocessing on the training corpus (all lowercase, no punctuation, tokenization, stemming, and stopword removal) and obtain a binary document-term matrix. Train a logistic classifier with the 'Label' as target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q4_b:\n",
    "    \n",
    "    def __init__(self,data, target ):\n",
    "        self.target = target\n",
    "        self.data = data\n",
    "    \n",
    "    def run(self):\n",
    "        actual_analyzer = HashingVectorizer(stop_words='english', binary=True, preprocessor=lambda line: line.translate(str.maketrans('', '', string.punctuation))).build_analyzer()\n",
    "        snowball_stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "        pipe = Pipeline([('vectorizer',HashingVectorizer(analyzer = lambda doc: (snowball_stemmer.stem(w) for w in actual_analyzer(doc))))\\\n",
    "                         ,('logistic', Texts.default_regressor())])\n",
    "        self.classifier = pipe.fit(self.data, self.target)\n",
    "        return self\n",
    "\n",
    "        \n",
    "q4_b = Q4_b(*q4_a.train).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Model based on doc2vec\n",
    "\n",
    "- Perform preprocessing on the training corpus (all lowercase, no punctuation, tokenization, stemming, and stopword removal). \n",
    "- Obtain a doc2vec embedding in order to reduce the dimension of the document vector. Explain which vector size you use and why.\n",
    "- Use the doc2vec model you just trained to convert the training set to a set of document vectors.\n",
    "- Train a logistic classifier with 'Label' as target feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from numpy.random import RandomState\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import utils\n",
    "\n",
    "class Q4_c:\n",
    "    \n",
    "    def __init__(self,data, target ):\n",
    "        self.target = target\n",
    "        self.data = data\n",
    "    \n",
    "    def run(self):\n",
    "        docs = Q4_c.makeTaggedDocs(self.target,self.data)\n",
    "        d2vModel = Q4_c.d2vModel(docs)\n",
    "        Q4_c.train_model(d2vModel, docs)\n",
    "        \n",
    "        dData, dTarget = Q4_c.learningVector(d2vModel, docs)\n",
    "        log_reg = Texts.default_regressor()\n",
    "        self.d2vModel = d2vModel\n",
    "        self.classifier = log_reg.fit(dData, dTarget)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def learningVector(model,docs):\n",
    "        d2Vectors = [model.infer_vector(doc.words) for doc in docs]\n",
    "        targets = [doc.tags[0] for doc in docs]\n",
    "        return d2Vectors,targets\n",
    "    \n",
    "    def train_model(model,docs,n=30):\n",
    "        shuffle_state = RandomState(seed=rand_seed)\n",
    "        for _ in range(n):\n",
    "            model.alpha -= 0.002\n",
    "            model.min_alpha = model.alpha\n",
    "            model.train(utils.shuffle(docs, random_state=shuffle_state), total_examples=len(docs), epochs=1)\n",
    "                \n",
    "    \n",
    "    def makeTaggedDocs(target,data):\n",
    "        snowball_stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "        stops = frozenset(stopwords.words('english'))\n",
    "        lst = []\n",
    "        for t,d in zip(target,data):\n",
    "            lst.append(TaggedDocument(words=[snowball_stemmer.stem(w) for w in simple_preprocess(d) if w not in stops],tags=[t]))\n",
    "        return lst\n",
    "    \n",
    "    def d2vModel(docs, n = 300):\n",
    "        model = Doc2Vec(dm=0, vector_size=n, workers=Texts.cc, batch_words=1000)\n",
    "        model.build_vocab(docs)\n",
    "        return model\n",
    "        \n",
    "q4_c = Q4_c(*q4_a.train).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "For the following tasks, use the test data.\n",
    "\n",
    "(d) Predict the classification with the two models on the test data. Preprocess the data if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q4_d:\n",
    "    def __init__(self, testData, testTarget , models, d):\n",
    "        self.testData = testData\n",
    "        self.testTarget = testTarget\n",
    "        self.models = models\n",
    "        self.d2v = Q4_d.D2V(d)\n",
    "        \n",
    "    def run(self):\n",
    "        self.predictions = [model.predict(self.testData) for model in self.models]\n",
    "        self.d2v.run(self.testTarget, self.testData)\n",
    "        return self\n",
    "    \n",
    "    class D2V:\n",
    "        \n",
    "        def __init__(self, d):\n",
    "            self.d = d\n",
    "        \n",
    "        def run(self, testTarget, testData):\n",
    "            testDocs = Q4_c.makeTaggedDocs(testTarget,testData)\n",
    "            self.testVectors, self.testTargets = Q4_c.learningVector(self.d.d2vModel, testDocs)\n",
    "            self.prediction = list(self.d.classifier.predict(self.testVectors))\n",
    "            return self\n",
    "            \n",
    "     \n",
    "q4_d = Q4_d(*q4_a.test, [q4_b.classifier], q4_c).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: We run the prediction for each model and then create a doc2vec vectors and prediction in the D2V class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Obtain the confusion matrices for the two models and the prediction on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q4_e:\n",
    "    def __init__(self, target, predictions, d2v):\n",
    "        self.target = target\n",
    "        self.predictions = predictions\n",
    "        self.d2v = d2v\n",
    "\n",
    "    def run(self):\n",
    "        names = ['binary document-term model']\n",
    "        for name,prediction in zip(names, self.predictions):\n",
    "            print(name)\n",
    "            display(pd.crosstab(np.array(self.target), np.array(prediction), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "        print('word embedding model')\n",
    "        display(pd.crosstab(np.array(self.d2v.testTargets), np.array(self.d2v.prediction), rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "q4_e = Q4_e(q4_a.y_test, q4_d.predictions, q4_d.d2v).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Obtain accuracy and F1-score for the prediction of the two different models on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,  f1_score\n",
    "\n",
    "class Q4_f:\n",
    "    def __init__(self, target, predictions, d2v):\n",
    "        self.target = target\n",
    "        self.predictions = predictions\n",
    "        self.d2v = d2v\n",
    "        \n",
    "    def run(self):\n",
    "        names = ['binary document-term model']\n",
    "        for name,prediction in zip(names, self.predictions):\n",
    "            print(name)\n",
    "            print('\\taccuracy: ' , accuracy_score(self.target, prediction))\n",
    "            print('\\tf1: ' , f1_score(self.target, prediction, average='weighted'))\n",
    "            print()\n",
    "        print('word embedding model')\n",
    "        print('\\taccuracy: ' , accuracy_score(self.d2v.testTargets, self.d2v.prediction))\n",
    "        print('\\tf1: ' , f1_score(self.d2v.testTargets, self.d2v.prediction, average='weighted'))\n",
    "        \n",
    "q4_f = Q4_f(q4_a.y_test, q4_d.predictions, q4_d.d2v).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Briefly comment on the quality of the two models. Interpret the results retrieved in the evaluation part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:  The binary model outperforms the word embedding by a huge margin, for both accuracy and F1 score. However both models perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language model\n",
    "\n",
    "For the following tasks use the <b>sampled_data</b>.\n",
    "\n",
    "(h) Create two lists, one for ham and one for spam, containing all messages.\n",
    "For ham and spam separately, build a bigram language model using the initial dataset (before splitting to training and test data). Do not perform stemming nor stopword removal for this task, but apply other preprocessing steps, such as all to lowercase, no punctuation and tokenization. Use both right and left padding, and manage unknown terms by using a dedicated token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams, word_tokenize\n",
    "from nltk.util import pad_sequence\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "class Q4_h:\n",
    "    def __init__(self, trainSet, testSet, targetAuthors=['spam','ham'], n = 2, l_pad = Texts.left_padding, r_pad = Texts.right_padding):\n",
    "        self.authors = trainSet[1].append(testSet[1])\n",
    "        self.text = trainSet[0].append(testSet[0])\n",
    "        self.targetAuthors = targetAuthors\n",
    "        self.n = n\n",
    "        self.l_pad = l_pad\n",
    "        self.r_pad = r_pad\n",
    "        self.buildNGramModel = lambda x: pad_sequence(x, self.n, pad_left=True, pad_right=True, left_pad_symbol=self.l_pad, right_pad_symbol=self.r_pad)\n",
    "        \n",
    "    def run(self):\n",
    "        author_sentences = Q4_h.authorSentenceDict(self.authors,self.text)\n",
    "        self.models = dict()\n",
    "        self.vocabs = dict()\n",
    "        for targetAuthor in self.targetAuthors:\n",
    "            self.models[targetAuthor], self.vocabs[targetAuthor]  = padded_everygram_pipeline(self.n, [[word.lower()  for sentence in author_sentences[targetAuthor] for word in word_tokenize(sentence) if word.isalpha()]])\n",
    "        return self\n",
    "\n",
    "        \n",
    "    def authorSentenceDict(authors, texts):\n",
    "        d = dict()\n",
    "        for author, text in zip(authors,texts):\n",
    "            d[author] = d.get(author, ()) + tuple(sentence.strip() for sentence in text.split('.') if sentence.strip())\n",
    "        return d\n",
    "\n",
    "q4_h = Q4_h(q4_a.train, q4_a.test).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) For each message groups, use the correspondent language model from (h) to generate, using MLE, a sentence of fifteen words using the following terms as seed:\n",
    "- 'hello'\n",
    "- 'yes'\n",
    "- 'but'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "class Q4_i:\n",
    "    def __init__(self, models, vocabs, l_pad, starters=['hello','yes','but'],n=2, ln = 15):\n",
    "        self.models = models\n",
    "        self.starters = starters\n",
    "        self.vocabs = vocabs\n",
    "        self.l_pad = l_pad\n",
    "        #self.n = len(next(iter(models.values()))[0][0])\n",
    "        self.n = n\n",
    "        self.ln = 15\n",
    "    \n",
    "    def run(self):\n",
    "        for author in self.models:\n",
    "            print(author ,':')\n",
    "            lm = self.fit(author)\n",
    "            for starter in self.starters:\n",
    "                txt_seed = ([self.l_pad]*(self.n - 1)) + [starter]\n",
    "                print(f'{starter} (seed: {txt_seed})')\n",
    "                print('\\t', starter , ' '.join(lm.generate(text_seed=txt_seed, random_seed=rand_seed, num_words=self.ln)))\n",
    "        return self\n",
    "\n",
    "    def fit(self, author):\n",
    "        lm = MLE(self.n)\n",
    "        lm.fit(self.models[author], vocabulary_text=self.vocabs[author])\n",
    "        return lm\n",
    "\n",
    "    \n",
    "q4_i = Q4_i(q4_h.models, q4_h.vocabs, q4_h.l_pad).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(j) Build a trigram model with the same data as in the previous task. Use both right and left padding, and manage unknown terms by using a dedicated token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_j = Q4_h(q4_a.train, q4_a.test, n=3).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(k) For each message group (ham and spam), use the correspondent language model from the previous qustion to generate, using MLE, a sentence of fifteen words using the following terms as seed:\n",
    "- 'hello'\n",
    "- 'yes'\n",
    "- 'but'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q4_k = Q4_i(q4_j.models, q4_j.vocabs, q4_j.l_pad,n=3).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(l) Compare the quality of the generated text. Which model performs better? In general, which differences are there in using trigrams as opposed to bigrams?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The quality of the trigrams is surprisingly good, especially when considering that, the bigram models should perform better in theory, since the training dataset is relatively small. In this case, the trigram models may overfit and the propability of unseen trigrams rises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Process Mining (15 points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General investigation\n",
    "\n",
    "a) Import the event log from the <b>Quarantine_Log</b> csv file. Set the case ID to 'patient', Timestamp to 'timestamp' and Activity as 'activity'. Also, set the lifecyle column to the right attribute. Furthermore, identify the case attributes and set them to case attributes. Find the correct setting, so that the resource is understood as resource (compare with the documentation). Give some basic information:\n",
    "\n",
    "    - number of cases\n",
    "    - number of variants\n",
    "    - number of events\n",
    "    - the trace and event attribute names\n",
    "    - the number of resources\n",
    "    - the earliest timestamp and the latest timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pm4py\n",
    "import pandas as pd\n",
    "\n",
    "from pm4py.algo.filtering.log.variants import variants_filter\n",
    "from pm4py.algo.filtering.log.attributes import attributes_filter\n",
    "\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.log.util.sampling import sample_log\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "from pm4py.statistics.traces.log import case_statistics\n",
    "\n",
    "from pm4py.visualization.petrinet import visualizer as pn_vis_factory\n",
    "from pm4py.visualization.petrinet import visualizer as pn_visualizer\n",
    "\n",
    "from pm4py.evaluation.replay_fitness import evaluator as replay_fitness_evaluator\n",
    "\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "\n",
    "from pm4py.algo.conformance.tokenreplay import algorithm as token_replay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv = pd.read_csv('./Datasets/Quarantine_log.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_csv.rename(columns={'Patient': 'case:patient'}, inplace=True)\n",
    "log_csv.rename(columns={'Timestamp': 'time:timestamp'}, inplace=True)\n",
    "log_csv.rename(columns={'Activity': 'concept:name'}, inplace=True)\n",
    "log_csv.rename(columns={'Lifecycle': 'lifecycle:lifecycle'}, inplace=True)\n",
    "log_csv.rename(columns={'Resource': 'org:resource'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case ID is chosen as Patient\n",
    "parameters = {log_converter.Variants.TO_EVENT_LOG.value.Parameters.CASE_ID_KEY: 'case:patient'}\n",
    "log_csv = dataframe_utils.convert_timestamp_columns_in_df(log_csv) \n",
    "# Events are sorted according to timestamp\n",
    "log_csv = log_csv.sort_values('time:timestamp')\n",
    "# An event lot is created with patient as case identifier\n",
    "event_log = log_converter.apply(log_csv, parameters=parameters, variant=log_converter.Variants.TO_EVENT_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Printing all the feilds asked in the question\n",
    "print('Number of Cases = {}'.format(len(event_log)))\n",
    "\n",
    "print('Number of Variants = {}'.format(len(case_statistics.get_variant_statistics(event_log))))\n",
    "\n",
    "print('Number of Events = {}'.format(log_csv.shape[0]))\n",
    "\n",
    "event_log[10].attributes.keys()\n",
    "for i,j in enumerate(event_log[10].attributes.keys()):\n",
    "    print(\"Trace attributes {}: {}\".format(i,j))\n",
    "\n",
    "event_attributes_list = []\n",
    "for event in event_log[10][0]:\n",
    "    event_attributes_list.append(event)\n",
    "    \n",
    "for i,event in enumerate(set(event_attributes_list)):\n",
    "    print('Event Attributes {} is {}'.format(i,event))\n",
    "    \n",
    "resources = attributes_filter.get_attribute_values(event_log, \"org:resource\")\n",
    "print('Number of Resourses {}'.format(len(resources.keys())))\n",
    "\n",
    "print('Earliest timestamp {}'.format(event_log[0][0]['time:timestamp']))\n",
    "print('Last timestamp {}'.format(event_log[-1][-1]['time:timestamp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the event log\n",
    "(b) Create a sample of the event log (<b>log_sampled</b>) containing 80% of the traces. Export the sampled event log.\n",
    "\n",
    "<font color='red'>Important!</font> Make sure that you submit your extracted event log with your results in Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "def get_sampled_log(full_log, fn = './output/5/log_sampled.xes'):\n",
    "    if path.isfile(fn):\n",
    "        sampled = xes_importer.apply(fn)\n",
    "    else:\n",
    "        N = len(event_log)\n",
    "        N_sampled = int(N*0.8)\n",
    "        sampled = sample_log(event_log, no_traces=N_sampled)\n",
    "        xes_exporter.apply(sampled,fn)\n",
    "    return sampled\n",
    "log_sampled = get_sampled_log(event_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace frequency\n",
    "(c) Use the sampled event log and print the least frequent and the most frequent variant and the corresponding counts. Is there already some indication about the model structure (e.g. loops, parallel, etc.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "# Obtaining all the variants (with varient of a trice and number of cases in that particular varient)\n",
    "variants = case_statistics.get_variant_statistics(log_sampled) \n",
    "print(variants[0])\n",
    "\n",
    "num_var = len(variants)\n",
    "\n",
    "# Seperating count and varients\n",
    "import numpy as np\n",
    "all_varients = []\n",
    "count_all_varients = [] \n",
    "for varient in variants:\n",
    "    all_varients.append(varient['variant']) \n",
    "    count_all_varients.append(varient['count'])\n",
    "\n",
    "a = np.array(count_all_varients)\n",
    "\n",
    "# Finding index of smallest and largest varient\n",
    "max_index = np.argmax(a)\n",
    "min_index = np.argmin(a)\n",
    "\n",
    "# Storing bigger and smaller varients seperately\n",
    "biggest_varient = all_varients[max_index]\n",
    "smaller_varients = all_varients[min_index:]\n",
    "\n",
    "# Printing\n",
    "print('Total Variants {}'.format(num_var))\n",
    "print('Most freq Variant count {}'.format(a[max_index]))\n",
    "print('Least freq Variants count {}'.format(a[min_index]), '\\n')\n",
    "\n",
    "print('Most Frequent Varient : ' , '\\n' )\n",
    "print(biggest_varient,'\\n')\n",
    "\n",
    "print('Least Frequent Varients : ' , '\\n' )\n",
    "for sv in smaller_varients:\n",
    "    print(sv, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: By looking into the most frequent variant as an example, we can indicate that there are few loops such as Register, Register and Initial Exam is looped and visited again as exclusive choice along with many sequential activities.   \n",
    "Further, we can observe that there is a similar behaviour in most of the least variant sequences, so it's safe to say this behaviour is general in most of the variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter event logs\n",
    "(d) Create three different event logs:\n",
    "\n",
    "1. One event log containing only the 10% of the most frequent traces (**filtered_log_variants**).\n",
    "2. One event log containing only patients with private insurance (**filtered_log_insurance**).\n",
    "3. One event log containing only patients having the event attribute type as 'cloud' (**filtered_log_cloud**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = attributes_filter.get_attribute_values(log_sampled, \"concept:name\")\n",
    "resources = attributes_filter.get_attribute_values(log_sampled, \"org:resource\")\n",
    "#print( 'activities', activities, '\\n')\n",
    "#print('resourses',resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # your code\n",
    "\n",
    "filtered_log_variants = variants_filter.filter_log_variants_percentage(log_sampled,percentage= 0.1)\n",
    "print('Size of filtered_log_variants',len(filtered_log_variants))\n",
    "\n",
    "list1 = ['PRIV']\n",
    "filtered_log_insurance = attributes_filter.apply(log_sampled, list1 , parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"Insurance\", attributes_filter.Parameters.POSITIVE: True})\n",
    "print('Size of filtered_log_insurance',len(filtered_log_insurance))\n",
    "\n",
    "list2 = ['cloud']\n",
    "filtered_log_cloud =  attributes_filter.apply(log_sampled, list2 , parameters={attributes_filter.Parameters.ATTRIBUTE_KEY: \"Type\", attributes_filter.Parameters.POSITIVE: True})\n",
    "print('Size of filtered_log_cloud',len(filtered_log_cloud))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovery and conformance checking\n",
    "\n",
    "(e) Use the Inductive Miner to discover a process model (Process tree or Petri net) for each event log created in (d). For one of the models - you may choose - explain shortly the behaviour of the model. (e.g. loops, sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "net1, initial_marking1, final_marking1 = inductive_miner.apply(filtered_log_variants)\n",
    "gviz_pn1 = pn_visualizer.apply(net1, initial_marking1, final_marking1)\n",
    "pn_visualizer.save(gviz_pn1, \"./output/5/filterd_log_variants.png\")\n",
    "pn_visualizer.view(gviz_pn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2, initial_marking2, final_marking2 = inductive_miner.apply(filtered_log_insurance)\n",
    "gviz_pn2 = pn_visualizer.apply(net2, initial_marking2, final_marking2)\n",
    "pn_visualizer.save(gviz_pn2, \"./output/5/filterd_log_insurance.png\")\n",
    "pn_visualizer.view(gviz_pn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3, initial_marking3, final_marking3 = inductive_miner.apply(filtered_log_cloud)\n",
    "gviz_pn3 = pn_visualizer.apply(net3, initial_marking3, final_marking3)\n",
    "pn_visualizer.save(gviz_pn3, \"./output/5/filterd_log_cloud.png\")\n",
    "pn_visualizer.view(gviz_pn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: First process model (i.e 10% of most frequent traces): From the process model (also saved as '.png') we can observe that many sequential activities such as register, initial exam, initial exam decision (could end up in a loop for few cases), after initial exam decision there is an exclusive choice for discharge and isolation. \n",
    "\n",
    "If the path for Discharge Init Exam is chosen, we see that for a few cases there is direct discharge. For others, there is a loop and also a parallel path which joins with the path of Inform about isolation activity. And finally, control call is looped and test3, test3 decision and discharge test are a sequential activities but there are cases with loops here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Briefly summarize the differences and similarities of the models. Why do they differ/are similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "Similarities: \n",
    "We see that irrespective of the filter used, we see that all the traces will have common activities such as register, init exam, discharge, control, testing etc. In all the cases there are sequential, looping, parallel and exclusive paths for activities.\n",
    "\n",
    "\n",
    "Differences:\n",
    "The major difference between first and second or third models is since the first model only considers the 10% of the most frequent traces, thus the model is much simpler (less branching and loops) when compared to second and third models. \n",
    "For, in the second case of private insurance, we consider about half of all the traces both frequent and less frequent, these less frequent cases will have too many activities (corner cases) which will result is complicated loops and branching. \n",
    "In the third case, we consider people using only cloud-based services, although the number of cases is less the path is both frequent and infrequent which causes complicated model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Perform the token-based replay for conformance checking using your discovered model for **filtered_log_variants** and the original event log. Does your process model fit the log? Explain the result in one sentence. Calculate the trace and log fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "print(filtered_log_variants[0], '\\n')\n",
    "token_replay_result = token_replay.apply(filtered_log_variants, net1, initial_marking1, final_marking1)\n",
    "print(token_replay_result[0], '\\n')\n",
    "\n",
    "fitness_tokenbasedreplay = replay_fitness_evaluator.apply(filtered_log_variants, net1, initial_marking1, final_marking1)\n",
    "print(fitness_tokenbasedreplay, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "print(event_log[0], '\\n')\n",
    "token_replay_result2 = token_replay.apply(event_log, net1, initial_marking1, final_marking1)\n",
    "print(token_replay_result2[0], '\\n')\n",
    "\n",
    "fitness_tokenbasedreplay2 = replay_fitness_evaluator.apply(event_log, net1, initial_marking1, final_marking1)\n",
    "print(fitness_tokenbasedreplay2, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The model has a low fitness because many of the traces in the original event log does not match the conformance that is obtained by the model generated using only the most frequent traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency and performance\n",
    "\n",
    "(h) Visualize the model for the **filtered_log_variants** event log enriched with frequency information. Subsequently, visualize that same model enriched with performance information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # your code\n",
    "parameters = {pn_visualizer.Variants.FREQUENCY.value.Parameters.FORMAT: \"png\"}\n",
    "gviz = pn_visualizer.apply(net1, initial_marking1, final_marking1, parameters=parameters, variant=pn_visualizer.Variants.FREQUENCY, log=filtered_log_variants)\n",
    "pn_visualizer.save(gviz, \"./output/5/flv_frequency.png\")\n",
    "pn_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {pn_visualizer.Variants.PERFORMANCE.value.Parameters.FORMAT: \"png\"}\n",
    "gviz = pn_visualizer.apply(net1, initial_marking1, final_marking1, parameters=parameters, variant=pn_visualizer.Variants.PERFORMANCE, log=filtered_log_variants)\n",
    "pn_visualizer.save(gviz, \"./output/5/flv_performance.png\")\n",
    "pn_visualizer.view(gviz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) What are frequent activities? Why may they be frequent (think about the real life process described by the log)? What are possibly problematic activities according to the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "Frequent activities represent the activities that are occurred most frequently in a log or activities frequent traces. \n",
    "They are frequent because they occur in many traces, in our case we show the frequency of the activities in 10% of the most frequent traces. \n",
    "By looking to the performance graphs, we see that before control call activity 2 hours is spent, test3 takes an hour and discharge init exam/test takes about half an hour, so there are the problematic activities based on performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 - Big Data (15 points): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: generating a simple log\n",
    "\n",
    "In this question, we use the event log from the log csv file with the following modifications:\n",
    "1. We flatten the lifecycles (i.e., start and complete) into a single event. Each event contains the start timestamp and complete timestamp.\n",
    "2. A new column, called ServiceTime column, is included which represents the duration of the corresponding activity in the event.\n",
    "\n",
    "We name the event log as **simple_log** in the remainder. Please follow the explanations below to prepare the **simple_log**. The preparation steps will not be graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use following utility functions for the modifications (these are given):\n",
    "def _distinguish_duplicate_activities(log):\n",
    "    \"\"\"Add flags to the duplicate activities in a trace in order to distinguish them\n",
    "\n",
    "    Keyword arguments:\n",
    "    log -- even log\n",
    "    \"\"\"\n",
    "    trace = list()\n",
    "    activity_list = list()\n",
    "    count=0\n",
    "    prev_caseid=\"\"\n",
    "    for row in log.itertuples():\n",
    "        activity=row.Activity\n",
    "        caseid=row.Patient\n",
    "        if(caseid!=prev_caseid):\n",
    "            count=0\n",
    "            prev_caseid=caseid\n",
    "            trace=[]\n",
    "\n",
    "        if activity in trace:\n",
    "            count+=1\n",
    "            activity = activity + \"-{}\".format(count)\n",
    "            \n",
    "        trace.append(activity)\n",
    "        activity_list.append(activity)\n",
    "    log[\"Activity\"] = activity_list\n",
    "    return log\n",
    "\n",
    "def _merge_lifecylces(log):\n",
    "    \"\"\"Merge lifycycles (start,complete) into a single event. \n",
    "\n",
    "    Keyword arguments:\n",
    "    log -- even log\n",
    "    \"\"\"\n",
    "    start_log = log.loc[log[\"Lifecycle\"]==\"start\"]\n",
    "    start_log = _distinguish_duplicate_activities(start_log)\n",
    "    \n",
    "    complete_log = log.loc[log[\"Lifecycle\"]==\"complete\"]\n",
    "    complete_log = _distinguish_duplicate_activities(complete_log)\n",
    "\n",
    "    complete_log[\"CompleteTime\"] = complete_log[\"ModelTime\"]\n",
    "    simple_log = start_log.merge(complete_log, left_on=['Patient',\"Activity\"], right_on=['Patient',\"Activity\"],suffixes=(\"\", \"_y\"))\n",
    "    simple_log.drop(simple_log.filter(regex='_y$').columns.tolist(),axis=1, inplace=True)\n",
    "    simple_log[\"ServiceTime\"] = simple_log[\"CompleteTime\"] - simple_log[\"ModelTime\"]\n",
    "    return simple_log\n",
    "\n",
    "def produce_simple_log(filepath):\n",
    "    \"\"\"Produce simple log where the lifecycles are merged and service time information is added\n",
    "\n",
    "    Keyword arguments:\n",
    "    filepath -- path to event log\n",
    "    \"\"\"\n",
    "    log = pd.read_csv(filepath, sep=',')\n",
    "    log.sort_values(by=[\"Patient\",\"ModelTime\"],inplace=True)\n",
    "    simple_log = _merge_lifecylces(log)\n",
    "    return simple_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation step 1**: Replace the filepath to your own filepath to produce the **simple_log**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#your filepath\n",
    "filepath = \"./Datasets/Quarantine_log.csv\"\n",
    "simple_log = produce_simple_log(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: expanding the event log\n",
    "\n",
    "In this question, we generate 100 event logs based on the <b>simple_log</b>. Each log replicates the base log (i.e., the <b>simple_log</b>). For randomization, you need to use the sum of the group's matriculation numbers (e.g., a group with 3 students having \"100000\", \"100001\", and \"100002\" as their matriculation numbers will use \"300003\" for the randomization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use following utility functions for the modifications (these are given):\n",
    "import random\n",
    "def _randomize_case_attribute(log,matriculation_num):\n",
    "    \"\"\"Randomize case attributes based on the matriculation number\n",
    "\n",
    "    Keyword arguments:\n",
    "    log -- event log\n",
    "    matriculation_num - sum of matriculation numbers\n",
    "    \"\"\"\n",
    "    random.seed(matriculation_num)\n",
    "    caseids = set(log[\"Patient\"])\n",
    "    for caseid in caseids:\n",
    "        random_val = random.randint(-3,3)\n",
    "        random.seed(random_val)\n",
    "        log.loc[log[\"Patient\"]==caseid,\"Age\"] = log.loc[log[\"Patient\"]==caseid,\"Age\"]+random_val\n",
    "    return log\n",
    "\n",
    "def _extract_log(log,iter_num):\n",
    "    \"\"\"Extract n-th log to ./generated_logs/\n",
    "\n",
    "    Keyword arguments:\n",
    "    log -- event log\n",
    "    iter_num -- n-th iteration\n",
    "    \"\"\"\n",
    "    log.to_csv(\"./generated_logs/generated_log-{}.tsv\".format(iter_num),header=False,index=False, sep=\"\\t\",line_terminator=\"\")\n",
    "\n",
    "def generate_log(original_log,num_replication,mat_num):\n",
    "    \"\"\"Generate logs (randomized by the matriculation number and extracted to ./generated_logs/) \n",
    "\n",
    "    Keyword arguments:\n",
    "    log -- event log\n",
    "    num_replication -- number of generated logs\n",
    "    mat_num -- sum of matriculation numbers\n",
    "    \"\"\"\n",
    "    import os\n",
    "    dir_path = \"./generated_logs\"\n",
    "    try:\n",
    "        os.mkdir(dir_path)\n",
    "    except OSError:\n",
    "        print (\"Directory already exists: %s\" % dir_path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % dir_path)\n",
    "    \n",
    "    base_log = original_log.copy(deep=True)\n",
    "    max_modeltime = max(base_log[\"ModelTime\"])\n",
    "    max_patientid = max(base_log[\"Patient\"])\n",
    "    for i in range(num_replication):\n",
    "        generated_log = base_log\n",
    "        generated_log[\"Patient\"] += max_patientid\n",
    "        generated_log[\"ModelTime\"] += max_modeltime\n",
    "        random.seed(None)\n",
    "        randomized_log = _randomize_case_attribute(generated_log,random.randint(0,mat_num))\n",
    "        _extract_log(randomized_log,i)\n",
    "        print (\"Successfully created %i th log at %s \"% (i,dir_path))\n",
    "        base_log = randomized_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation step 2**: Generate 100 replicated logs in your local disk (./generated-logs/generated-log-0.tsv, ./generated-logs/generated-log-1.tsv, ..., ./generated-logs/generated-log-99.tsv). Do not forget to replace the SUM_MAT_NUM to yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your group's sum\n",
    "SUM_MAT_NUM = 1209550 \n",
    "base_log = simple_log[[\"Patient\", \"ModelTime\",\"Activity\",\"Age\",\"ServiceTime\"]] # this will be removed\n",
    "NUM_REPITITION=100\n",
    "generate_log(base_log,NUM_REPITITION,SUM_MAT_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Hadoop\n",
    "\n",
    "(a) Now, it's time to work with the Hadoop system. The goal of this task is to merge 100 event logs at your disk in the Hadoop system. Follow the instructions below and show your results in each step (screenshots of the command line). We use \"letter identifier\" for this task (The letter identifier is the string consisting of the first letters of the group memebers' first names, e.g., for the group with \"Alessandro Berti\", \"Bernardo Silva\", \"Chiao Li\", the indentifier is \"ABC\").\n",
    "\n",
    "    1) Import the event logs to your Docker engine (at /usr/local/hadoop/(identifier)-generated-logs/).\n",
    "    2) Upload the files to the running Hadoop system (at /input/(identifier)-generated-logs/). \n",
    "    3) Merge the file and copy the result back to the Hadoop system (at /input/(identifier)-final-log.tsv).\n",
    "    4) Using the Hadoop command, print out the merged file in the command line (the screenshot may contain 10 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "from IPython.display import Image\n",
    "Image(filename='./output/screens/6_a_import.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "Image(filename='./output/screens/6_a_upload.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "Image(filename='./output/screens/6_a_merge.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "Image(filename='./screens/6_a_content.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Discovery\n",
    "\n",
    "(b) Discover a process model from the merged file using MapReduce algorithms. Explain how you discover the process model with the following deliverables:\n",
    "\n",
    "    1) Mapper function (as python file(s))\n",
    "    2) Reducer function (as python file(s))\n",
    "    3) Hadoop commands for MapReduce calculation (as text file)\n",
    "    4) Jupyter notebook code that prints the directly-follows relations and discover process models based on the directly-follows relations (you are free to use any discovery algorithms)\n",
    "\n",
    "<font color='red'>Important!</font> Please note that in this task, your result will be evaluated based on whether they are reproducible from your explanation. If you skip MapReduce calculations for this task, you will get 0 points.The deliverables of 1), 2), and 3) should be submitted as outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "dfg = dict()\n",
    "with open('./output/6_b/dfg.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        dfg[(row[0],row[1])] = int(row[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.visualization.dfg import visualizer as dfg_vis\n",
    "\n",
    "\n",
    "gviz = dfg_vis.apply(dfg)\n",
    "dfg_vis.view(gviz)\n",
    "dfg_vis.save(gviz, './output/6_b/dfg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.algo.discovery.inductive import algorithm as alg\n",
    "from pm4py.visualization.petrinet import visualizer as petri_vis\n",
    "\n",
    "disco = alg.apply_dfg(dfg)\n",
    "disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gviz = petri_vis.apply(*disco)\n",
    "print('Visualization generated, saving now')\n",
    "petri_vis.save(gviz, './output/6_b/petri.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analysis\n",
    "\n",
    "(c) Calculate the total service time for each case using MapReduce algorithms. Explain how you calculate the total service time for each case with the following deliverables:\n",
    "\n",
    "    1) Mapper function (as python file(s))\n",
    "    2) Reducer function (as python file(s))\n",
    "    3) Hadoop commands for MapReduce calculation (as text file)\n",
    "    4) Result: total service times for cases (as text file)\n",
    "    \n",
    "Important! Please note that in this task, your result will be evaluated based on whether they are reproducible from your explanation. If you skip MapReduce calculations for this task, you will get 0 points.The deliverables of 1), 2), 3), and 4) should be submitted as outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Visualize 1000 cases with the longest total service time using any chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./output/6_c/service_times.csv', names=['CaseID', 'Service Time'], index_col=0)\n",
    "sns.displot(data=df.nlargest(1000,columns=['Service Time']), kind='kde')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
